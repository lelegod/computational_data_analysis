{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests \n",
    "\n",
    "# seaborn can be used to \"prettify\" default matplotlib plots by importing and setting as default\n",
    "import seaborn as sns\n",
    "sns.set() # Set searborn as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('sand.mat')\n",
    "X = mat['X']\n",
    "y = mat['Y'].ravel()\n",
    "\n",
    "[n, p] = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Perform univariate feature selection for the sand data using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (a) Bonferroni correction to control the family-wise error rate(FWER). Use FWER = 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features after correcting with Bonferroni correction: 72.\n"
     ]
    }
   ],
   "source": [
    "PValues = np.zeros(p)\n",
    "Xsub = np.zeros(p)\n",
    "\n",
    "for j in range(p):\n",
    "    Xsub = X[:,j]\n",
    "    # Use the stats models linear regression, since p value already is included\n",
    "    # Otherwise check https://stackoverflow.com/questions/27928275/find-p-value-significance-in-scikit-learn-linearregression\n",
    "    # Which explains how to expand the class in sklearn to calculate it\n",
    "    slope, intercept, r_value, PValues[j], std_err = linregress(Xsub, y)\n",
    "\n",
    "# Sort p-values in acending order\n",
    "idx1 = np.argsort(PValues)\n",
    "p = PValues[idx1]\n",
    "\n",
    "remaining_features_bonf = len(np.where(p < (0.05 / 2016))[0]) # Amount af features included\n",
    "print(f'Remaining features after correcting with Bonferroni correction: {remaining_features_bonf}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (b) Benjamini-Hochbergâ€™s algorithm for FDR. Use an acceptable fraction of mistakes,\n",
    "q = 0.15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features after applying DFR: 721.\n"
     ]
    }
   ],
   "source": [
    "FDR = multipletests(PValues, alpha = 0.05, method = \"fdr_bh\")[1] # Computing Benjamini Hochberg's FDR\n",
    "\n",
    "idx2 = np.argsort(FDR)\n",
    "fdr = FDR[idx2]\n",
    "\n",
    "remaining_features_fdr = len(np.where(fdr < 0.15)[0]) # How many values are below 0.15?\n",
    "print(f'Remaining features after applying DFR: {remaining_features_fdr}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the solutions in terms of number of selected features and selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It is clear that FDR \"allows\" for more features to be kept in the model, and through this the chance of having false discoveries are higher, this is done to make sure that all significant features are kept in the model, whereas bonferroni might remove some significant features because of the more stringent cutoff.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
